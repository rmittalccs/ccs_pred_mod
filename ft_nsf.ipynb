{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed266230-844d-49ef-b83f-26c3c2170053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import chardet\n",
    "#os.chdir(\"nsf\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd8f65b-8c96-4a67-9d20-6469525aca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import xgboost as xgb\n",
    "import multiprocessing\n",
    "#import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold, chi2, f_regression, r_regression, RFECV, RFE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model, tree, ensemble\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4bf7de-f22f-4f87-b1de-e789263570d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = preprocessing.OrdinalEncoder()\n",
    "# X = np.array([10, 20, 35, 55, 100])\n",
    "\n",
    "# # Initialize the StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Fit the scaler to your data and transform it\n",
    "# ss_scaled = scaler.fit_transform(X.reshape(-1,1))\n",
    "# ss_enc = enc.fit_transform(X.reshape(-1,1))\n",
    "\n",
    "# ss_scaled, ss_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9027ef60-fb4f-40a0-9eac-c8cec0a27317",
   "metadata": {},
   "source": [
    "### **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44760d1c-115e-4100-abdb-ad0197517e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "\n",
    "def melt_ntop(df, ntop=5, column = \"first_gift_fund\"):\n",
    "\n",
    "    # make everything lower case\n",
    "    if not is_numeric_dtype(df[column]):\n",
    "        df[column] = df[column].str.lower()\n",
    "    \n",
    "    # Filter out rows with NA values in column\n",
    "    threshold = len(df) * 0.05\n",
    "\n",
    "    df_ntop = df.dropna(subset=[column]) \\\n",
    "        .groupby(column) \\\n",
    "        .filter(lambda x: len(x) > threshold) \\\n",
    "        .groupby(column) \\\n",
    "        .size() \\\n",
    "        .sort_values(ascending=False) \\\n",
    "        .reset_index(name='count')\n",
    "    \n",
    "    # Get the top 5 funds\n",
    "    top_vars = df_ntop[column].tolist()    \n",
    "    \n",
    "    # Create new columns for each of the top 5 funds\n",
    "    for var in top_vars:\n",
    "        var_str = str(var).replace(\".\", \"_\").replace('@', '_').replace(' ', '_')\n",
    "        var_column_name = \"%s_%s_binary\" %(column, var_str)\n",
    "        var_column_name = var_column_name.replace('__', '_')\n",
    "        df[var_column_name] = df[column].apply(lambda x: 1 if x == var else 0)\n",
    "\n",
    "    df = df.drop(columns=column)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "def calculate_age(birth_date):\n",
    "    if isinstance(birth_date, str):\n",
    "        birth_date = datetime.strptime(birth_date, '%Y-%m-%d')\n",
    "        today = datetime.now()\n",
    "        age = today.year - birth_date.year - ((today.month, today.day) < (birth_date.month, birth_date.day))\n",
    "        fraction = (today - birth_date.replace(year=today.year)).days / 365.25\n",
    "        age_decimal = age + fraction\n",
    "        return age_decimal\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def bin_and_convert_to_binary(ages):\n",
    "\n",
    "    # Define bin edges\n",
    "    bin_edges = [0, 30, 40, 50]\n",
    "\n",
    "    # Bin the ages into groups\n",
    "    binned_ages = np.digitize(ages, bins=bin_edges)\n",
    "    \n",
    "    # Convert binned ages into binary representation\n",
    "    binary_ages = np.eye(len(bin_edges) + 1)[binned_ages]\n",
    "    \n",
    "    return binary_ages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c72b5-1805-44e2-9ed9-ac87214f327a",
   "metadata": {},
   "source": [
    "### **Constituent File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4303cd75-3c92-4a7f-a836-e3fea3676d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/RMittal@ccsfundraising.com/ccs_pred_mod\"\n",
    "filename =  \"national_scleroderma_foundation_constituent_ccsdb.csv\"\n",
    "file = \"%s/%s\" %(path, filename)\n",
    "df_cd = pd.read_csv(file, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1508a2b7-bbf1-46dc-8f3f-1deefb21a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cd = df_cd.merge(final1[[\"constituent_id\", \"first_gift_fund_1_0002_binary\",\n",
    "#  \"last_gift_fund_1_0002_binary\", \"largest_gift_fund_1_0002_binary\"]], on=\"constituent_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b42c7f7f-d053-4178-9c69-43e100d88f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with less than 5% non-empty values\n",
    "#cleaned_df = df_cd.dropna(axis=1, thresh=len(df_cd)*0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb109a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ccecf10-c6ab-4a6a-9fa9-b70d129b6dde",
   "metadata": {},
   "source": [
    "### **Drop unwanted columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d0ea1d1-d1be-4913-9014-ac5c8df00c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Unnamed\n",
    "columns_to_drop=[\"Unnamed: 0\", \"org_name\", \"wealth_screen_data\", \"attributes\"]\n",
    "for col in columns_to_drop:\n",
    "    if col in df_cd.keys().to_list():\n",
    "        df_cd = df_cd.drop(columns=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753766e7-9426-4508-ac9a-0ec7fa00858e",
   "metadata": {},
   "source": [
    "### **Spouse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2b7f67d-d3db-4a70-a7db-6afd5ac9c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "### has_spouse_binary\n",
    "df_cd[\"has_spouse_binary\"] =  df_cd.filter(like='spouse').notna().any(axis=1).astype(int)\n",
    "columns_to_drop = [\"spouse_id\", \"spouse_name\", \"spouse_business_name\", \\\n",
    "                   \"spouse_business_title\", \"spouse_email\"]\n",
    "df_cd = df_cd.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1254aae0-bf73-4e99-bb0f-6986876a8bc4",
   "metadata": {},
   "source": [
    "### **Date to Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7143e46-4664-4016-bdb8-10044c82ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date of Birth to Age in Decimal\n",
    "columns_age = [\"age\", \"spouse_age\"]\n",
    "for col in columns_age:\n",
    "    df_cd[col] = pd.to_datetime(df_cd[col])\n",
    "    dob_array = df_cd[col]\n",
    "    ages_decimal = np.array([\"%2.2f\" %((today - dob).days/365.25) for dob in dob_array]).astype(float)\n",
    "    ages_decimal[ages_decimal < 0] = np.nan\n",
    "#    ages_decimal = [calculate_age(date) for date in dob]\n",
    "    df_cd = df_cd.drop(columns=[col])\n",
    "    df_cd[col] = ages_decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8ed57d-28a6-4686-9575-9625866d7c53",
   "metadata": {},
   "source": [
    "### **Age Binning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a398ab89-15fa-4504-b31f-e16e713b6d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"age\"\n",
    "bin_edges = [0, 30, 40, 50, 200]\n",
    "A = pd.cut(df_cd[col], bins=bin_edges, labels=False, right=False)\n",
    "\n",
    "# Convert binned ages into binary representation\n",
    "binary_ages = pd.get_dummies(A, prefix=col)\n",
    "\n",
    "# Join the binary columns to the original DataFrame\n",
    "df_cd = pd.concat([df_cd, binary_ages], axis=1)\n",
    "\n",
    "# Rename the binary columns\n",
    "binary_column_names = [\"%s_%s_binary\" %(col, edge) for edge in bin_edges[1:]]\n",
    "column_mapping = {binary_ages.keys().to_list()[i]:binary_column_names[i] for i in range(len(binary_ages.keys()))}\n",
    "df_cd.rename(columns=column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b69baf3-20d7-4208-b199-1e1f77035a0e",
   "metadata": {},
   "source": [
    "### **Dates to Days**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3600552d-f9be-4bea-ab78-a145a9f95115",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dates = [key for key in df_cd.keys() if \"date\" in key.lower()] + [\"class_year\"]\n",
    "for col in column_dates:\n",
    "#    print(col)\n",
    "    df_cd[col] = pd.to_datetime(df_cd[col])\n",
    "    col_days = (today - df_cd[col]).dt.days\n",
    "    col_days[col_days < 0] = np.nan\n",
    "    df_cd = df_cd.drop(columns=col)\n",
    "    df_cd[col] = col_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48298959-ff9d-401f-b33b-4e3c570a56a3",
   "metadata": {},
   "source": [
    "### **Prefix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9d0838f-bb9e-4963-a1f3-371ee3e61295",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd[\"prefix\"] = df_cd[\"prefix\"].astype(str)\n",
    "df_cd[\"prefix_has_dr_binary\"] = df_cd[\"prefix\"].str.contains(r\"(dr|prof)\", case=False).astype(int)\n",
    "df_cd = df_cd.drop(columns=[\"prefix\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9267436-78ee-432c-bea1-54c277936800",
   "metadata": {},
   "source": [
    "### **Incomplete address**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a407168b-7c5e-4bd9-9381-c13fafbf2013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd[\"incomplete_address_binary\"] = ((df_cd['address_1'].isna()) | (df_cd['home_city'].isna()) | \\\n",
    "                               (df_cd['home_state'].isna()) | (df_cd['zip'].astype(str).str.len() < 5)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a9e46-e4e6-45bc-8ecf-73acf9bda0f5",
   "metadata": {},
   "source": [
    "### **Presence/Absence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8be20877-d917-43a3-96e9-ea28a1ed76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_binaries = [\"middle_name\", \"address_2\", \"head_of_household\", \"number_of_children\", \\\n",
    "                    \"history_of_volunteer\", \"employer_name\", \"business_address\", \\\n",
    "                    \"seasonal_address\", \"business_email\", \\\n",
    "                    \"home_phone\", \"cell_phone\", \"business_phone\"]\n",
    "# Convert non-null entries into binary columns\n",
    "binary_df = pd.get_dummies(df_cd[columns_binaries].notnull().astype(int))\n",
    "column_mapping = {key:\"%s_binary\" %key for key in binary_df.keys()}\n",
    "binary_df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Drop the original columns\n",
    "df_cd = df_cd.drop(columns=columns_binaries)\n",
    "\n",
    "# Concatenate the binary columns with the original DataFrame\n",
    "df_cd = pd.concat([df_cd, binary_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c994ca2b-d1cb-43e8-af4c-9b55a467a19c",
   "metadata": {},
   "source": [
    "### **TOP 5 BINARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f79e4f0c-e536-44f2-aea5-7c9468cdc24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Any Columns with Email\n",
    "#col_emails = [key for key in df_cd.keys() if \"email\" in key.lower()]\n",
    "col_emails = [\"personal_email\"]\n",
    "for col in col_emails:\n",
    "#    print(col)\n",
    "    df_cd[col] = df_cd[col].astype(str)\n",
    "    if len(df_cd[df_cd[col].notna()]) & len(df_cd[df_cd[col]!=\"nan\"])>0:\n",
    "        col_type = df_cd[col].str.split(pat=\"@\", expand=True)[1]\n",
    "        df_cd = df_cd.drop(columns=col)\n",
    "        df_cd[col] = col_type\n",
    "        df_cd = melt_ntop(df=df_cd, ntop=5, column=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79f18c41-4a48-4e72-8d61-fc99353e390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constit_data[\"home_state\"].value_counts()\n",
    "columns = [\"home_city\", \"home_state\", \"suffix\", \"last_action_type\", \"marital_status\",\\\n",
    "          \"constituent_type_1\", \"constituent_type_2\", \"number_of_special_events_attended\"]\n",
    "for col in columns:\n",
    "    #print(col)\n",
    "    df_cd = melt_ntop(df=df_cd, ntop=5, column=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0c959f-1dea-4429-a606-4248862a22a1",
   "metadata": {},
   "source": [
    "### **Filters and Indicators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a4ce7b3-5fb9-4cfb-a531-ed0a84cc4953",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd = df_cd.drop(columns=[\"is_deceased\", \"is_individual\"])\n",
    "df_cd = df_cd[(df_cd[\"deceased\"].str.contains(\"no\", case=False)) & \\\n",
    "              (df_cd[\"key_indicator\"].str.contains(\"I\", case=False)) &\\\n",
    "              (df_cd[\"home_country\"].str.contains(\"USA|U\\.S\\.A\\.|United States|America\", case=False)) ]\n",
    "df_indicators = pd.concat([df_cd.pop(col) for col in [\"deceased\", \"key_indicator\"]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a06673-e7cc-476f-81c3-bea61662202a",
   "metadata": {},
   "source": [
    "### **Taggers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea7625a8-c25e-4c81-b285-acfef36da418",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_taggers = [\"constituent_id\", \"first_name\", \"last_name\", \"home_country\", \"address_1\", \"zip\",\\\n",
    "                  \"current_trustee\", \"past_trustee\", \"assigned_manager\", \\\n",
    "                  \"lifetime_hard_credits\", \"lifetime_soft_credits\", \\\n",
    "                  \"first_gift_amount\", \"most_recent_gift_amount\", \"number_of_gifts\"]\n",
    "df_taggers = pd.concat([df_cd.pop(col) for col in column_taggers], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a3d54-d35b-4aaa-9f0f-c7f4c8d37c2f",
   "metadata": {},
   "source": [
    "### **Sklearn -- preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1db627dd-2391-4343-9930-102ae17830dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop all columns that are NaN\n",
    "df_reg = df_cd.dropna(how=\"all\", axis=1)\n",
    "\n",
    "### Drop all columns where 80% of the entires are NaN\n",
    "df_reg = df_reg.dropna(axis=1, thresh=len(df_reg)*0.20)\n",
    "\n",
    "### Convert the lifetime giving into log1p\n",
    "df_reg[\"lifetime_giving\"] = np.log1p(df_reg[\"lifetime_giving\"])/np.log(10)\n",
    "\n",
    "columns_binary = [key for key in df_reg.keys() if \"binary\" in key.lower()]\n",
    "if len(columns_binary)>0:\n",
    "    df_reg_subset = pd.concat([df_reg.pop(col) for col in columns_binary], axis=1)\n",
    "else:\n",
    "    df_reg_subset = pd.DataFrame()\n",
    "df_reg_subset[\"m_giving_logp1\"] = df_reg.pop(\"lifetime_giving\")\n",
    "\n",
    "X = df_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6a4d889-c159-4b14-b57a-ea82949cf838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the predictors (scaling numeric variables and encoding categorical variables, feature_selection etc)\n",
    "#numeric_features = X.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "#categorical_features = X.select_dtypes(include=[\"object\", \"string\", \"O\"]).columns.tolist()\n",
    "numeric_features = [col for col in X.columns if is_numeric_dtype(X[col])]\n",
    "categorical_features = [col for col in X.columns if not is_numeric_dtype(X[col])]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehotencoder', OneHotEncoder(min_frequency=0.05))\n",
    "    # You may need to add encoding steps for categorical features here\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "#X_processed = np.hstack((np.array(y)[:, np.newaxis], X_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09a48847-eff9-4014-925a-080b29748193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset indices of X_processed and df_reg_subset\n",
    "df_reg_subset = df_reg_subset.reset_index(drop=True)\n",
    "\n",
    "final = pd.concat([pd.DataFrame(data=X_processed, columns=X.columns), \\\n",
    "                             df_reg_subset], axis=1)\n",
    "final = final.dropna(how=\"any\")\n",
    "m_giving_logp1 = final.pop('m_giving_logp1')\n",
    "#final.isnull().sum().any()\n",
    "#plt.figure(figsize=(4, 2))\n",
    "#final1.m_giving_logp1.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e65273f-8095-4fc5-9eae-6635ff8b0525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((151515, 44), (219102, 6), (219102, 39))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape, X_processed.shape, df_reg_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc636193-e631-4795-9126-0bfed0532f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(4, 2))\n",
    "# final.number_of_special_events_attended.hist(bins=100)\n",
    "# plt.yscale('log')\n",
    "\n",
    "# plt.figure(figsize=(4, 2))\n",
    "# plt.scatter(final.number_of_special_events_attended, m_giving_logp1)\n",
    "# plt.xlim(0, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac57d04-b631-43b3-9f92-27686ff72e8d",
   "metadata": {},
   "source": [
    "## **Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b37a175-8f3a-43ce-bb61-2bbffc2298c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### y\n",
    "y = m_giving_logp1\n",
    "### All columns\n",
    "xcol_all = final.keys().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a336ab1-8af4-4d7e-a806-de2517bd07b3",
   "metadata": {},
   "source": [
    "#### **Variance Threshold**\n",
    "Feature selector that removes all low-variance features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "898bb158-4940-4f15-a975-e5c74d8d892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "29\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "X = final[xcol_all]\n",
    "for threshold in [0.01, 0.05, 0.1]:\n",
    "#    threshold = 0.05\n",
    "    selector = VarianceThreshold(threshold=threshold)\n",
    "    X_reduced = selector.fit_transform(X, y)\n",
    "\n",
    "    cols = selector.get_support(indices=True)\n",
    "    ncols = len(cols)\n",
    "    globals() [\"xcol_var_%d\" %(threshold*100)] = X.iloc[:,cols].columns.tolist()\n",
    "    print(len(globals() [\"xcol_var_%d\" %(threshold*100)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0ea690-82d5-4c00-83a0-45bdf8074ea5",
   "metadata": {},
   "source": [
    "#### **F_Statistic Threshold**\n",
    "Univariate linear regression tests returning F-statistic and p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dafb0b6-7515-4797-ab40-f5d7fc90484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.01\n",
    "dfn = 1\n",
    "dfd = len(X) - 2\n",
    "f01 = sp.stats.f.isf(q, dfn, dfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f37e5f13-4ec5-478d-99dd-6ddb2400d8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final[xcol_all]\n",
    "f_stat, p_values = f_regression(X, y)\n",
    "cols_f_stat = list(np.where(f_stat>f01)[0])\n",
    "xcol_f_stat = X.iloc[:,cols_f_stat].columns.tolist()\n",
    "# plt.figure(figsize=(4, 2))\n",
    "# g = plt.hist(f_stat, bins=20, color=\"red\")\n",
    "len(xcol_f_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcecd4eb-4a11-41d9-8799-3948d1421257",
   "metadata": {},
   "source": [
    "#### **Pearson_R Threshold**\n",
    "Univariate linear regression tests returning the Pearson Correlation Coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c150c0d1-fc17-48a5-bbbb-2630e4a8a197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final[xcol_all]\n",
    "r_pearson = np.abs(r_regression(X, y))\n",
    "cols = list(np.where(r_pearson>=np.mean(r_pearson))[0])\n",
    "ncols = len(cols)\n",
    "xcol_rpearson_mean = X.iloc[:,cols].columns.tolist()\n",
    "len(xcol_rpearson_mean)\n",
    "#g = plt.hist(r_pearson, bins=20)\n",
    "#sns.boxplot(r_pearson)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9defcc3-fada-4717-b31e-9fdc151355dd",
   "metadata": {},
   "source": [
    "#### **Recursive Feature Elimination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dd4e326-e8ba-4f82-8811-fbec324858ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting xgb\n",
      "Optimal number of features: 35\n",
      "Estimator: xgb No_of_features: 35\n",
      "Fitting lm\n",
      "Optimal number of features: 6\n",
      "Estimator: lm No_of_features: 6\n",
      "CPU times: user 2min 50s, sys: 6.65 s, total: 2min 57s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "est_dict = {\"lm\": linear_model.LinearRegression(), \"xgb\": xgb.XGBRegressor(booster=\"gbtree\"), \\\n",
    "            \"xgbrf\": xgb.XGBRFRegressor(), \"svr\": SVR(kernel=\"linear\"), \\\n",
    "            \"rf\": RandomForestRegressor(n_estimators=100, oob_score=True, bootstrap=True, random_state=42)\n",
    "           }\n",
    "#            \"rf\": ensemble.RandomForestRegressor()}\n",
    "\n",
    "# est = \"svr\" ### Takes too long!! I had to stop after 15 minutes\n",
    "# est = \"rf\" ### Takes too long!! I had to stop after 15 minutes\n",
    "# est = \"lm\"\n",
    "# est = \"xgb\"\n",
    "\n",
    "#estimator = est_dict[est]\n",
    "\n",
    "run = True \n",
    "if run:\n",
    "    for est in [\"xgb\", \"lm\"]:\n",
    "        estimator = est_dict[est]\n",
    "        X = final[xcol_all]\n",
    "        y = m_giving_logp1\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "        #rfe = RFE(estimator=estimator, step=1, n_features_to_select=25, verbose=2)\n",
    "        rfe = RFECV(estimator=estimator, step=1, min_features_to_select=1, verbose=0, \\\n",
    "                    n_jobs=(multiprocessing.cpu_count()//2), cv=3,\\\n",
    "                    scoring=\"neg_mean_squared_error\")\n",
    "        print(\"Fitting %s\" %est)\n",
    "        rfe.fit(X=X_train, y=y_train)\n",
    "        print(f\"Optimal number of features: {rfe.n_features_}\")\n",
    "\n",
    "        cols = rfe.get_support(indices=True)\n",
    "        globals()[\"xcol_rfecv_%s\" %est] = X.iloc[:,cols].columns.tolist()\n",
    "        print(\"Estimator:\", est, \"No_of_features:\", len(cols))\n",
    "#    sum(rfe.ranking_==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90d81ea0-9d16-43cf-9f83-d45f6ad1034b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#np.abs(rfe.estimator_.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49d4bf52-b38e-4a61-b86f-31dbd2fca527",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Only for RFECV\n",
    "\n",
    "run=False\n",
    "if run:\n",
    "    n_scores = len(rfe.cv_results_[\"mean_test_score\"])\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Mean test accuracy\")\n",
    "    plt.errorbar(\n",
    "        range(0, n_scores),\n",
    "        rfe.cv_results_[\"mean_test_score\"],\n",
    "        yerr=rfe.cv_results_[\"std_test_score\"],\n",
    "    )\n",
    "    plt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c50c6a-f101-45a6-b68a-7be9d1f26cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = True\n",
    "if run:\n",
    "    folds = 5\n",
    "\n",
    "    ### X\n",
    "    features = {\"all\": xcol_all, \"var_1\": xcol_var_1, \"var_10\": xcol_var_10, \"var_5\": xcol_var_5, \\\n",
    "                \"f_stat\": xcol_f_stat, \"r_pearson\": xcol_rpearson_mean,\\\n",
    "                \"rfecv_xgb\": xcol_rfecv_xgb, \"rfecv_lm\": xcol_rfecv_lm}\n",
    "                # \"f_stat_med\": xcol_f_stat_med,\n",
    "\n",
    "    ### List of models to be tested\n",
    "    algorithms = {\"LR\": linear_model.LinearRegression(), \"GBR\": ensemble.GradientBoostingRegressor(), \\\n",
    "                \"XGBR\": xgb.XGBRegressor(), \"XGBRF\": xgb.XGBRFRegressor(),\\\n",
    "                \"DTR\": tree.DecisionTreeRegressor()}\n",
    "\n",
    "    # features = {\"rfecv_xgb\": xcol_rfecv_xgb, \"rfecv_lm\": xcol_rfecv_lm}\n",
    "    # algorithms = {\"XGBR\": xgb.XGBRegressor(), \"LR\": linear_model.LinearRegression()}\n",
    "\n",
    "    model_feature_importance = {}\n",
    "    model_pred = {}\n",
    "    model_stats = {}\n",
    "    model_evaluation = {}\n",
    "\n",
    "    y = m_giving_logp1\n",
    "    for feature_type, cols in features.items():\n",
    "        \n",
    "        X = final[cols]\n",
    "        \n",
    "        # Creating a training set index by partitioning the dataset\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "        #print(\"feature_type = %10s | No. of cols = %3d\" %(feature_type, len(cols)))\n",
    "    \n",
    "        model_feature_importance[feature_type] = {}\n",
    "        model_pred[feature_type] = {}\n",
    "        model_stats[feature_type] = {}\n",
    "        model_evaluation[feature_type] = {}\n",
    "        \n",
    "        globals() [\"model_df_%s\" %(feature_type)] = pd.DataFrame({\"Features\": X.keys().tolist()})\n",
    "        for algo_name, model in algorithms.items():\n",
    "            \n",
    "            ### Fitting\n",
    "            scores = cross_val_score(model, X_train, y_train, cv=folds, scoring='neg_root_mean_squared_error')\n",
    "            results = model.fit(X_train, y_train)\n",
    "            y_pred = results.predict(X_test)\n",
    "        \n",
    "            ### Statistics\n",
    "            # Calculate MAE, MSE and RMSE\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        \n",
    "            ### Populate the dictionaries and the dataframe\n",
    "\n",
    "            try:\n",
    "                if hasattr(model, 'feature_importances_'):\n",
    "                    model_feature_importance[feature_type][algo_name] = results.feature_importances_\n",
    "                elif hasattr(model, 'coef_'):\n",
    "                    model_feature_importance[feature_type][algo_name] = results.coef_.flatten()\n",
    "            #except AttributeError:\n",
    "            #    print(\"%s object has no attribute feature_importances_ or coef_\" %algo_name)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            #model_feature_importance[feature_type][algo_name]=results.feature_importances_\n",
    "            model_pred[feature_type][algo_name] = y_pred\n",
    "            model_stats[feature_type][algo_name] = [mae, mse, rmse]\n",
    "            model_evaluation[feature_type][algo_name] = -scores.mean()\n",
    "            print(feature_type, algo_name)\n",
    "            #, X_train.shape, len(cols), model_feature_importance[feature_type][algo_name])\n",
    "            \n",
    "            try:\n",
    "                globals() [\"model_df_%s\" %(feature_type)][\"Coeff_%s\" %algo_name] = model.coef_\n",
    "            except:\n",
    "                pass  \n",
    "\n",
    "    # Your list of tuples\n",
    "    data = [(key, len(features[key]), key1, model_stats[key][key1][2]) for key in model_stats.keys() for key1 in model_stats[key].keys()]\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"Feature_Selection\", \"N_Features\", \"Estimator\", \"Root_Mean_Square_Error\"])\n",
    "\n",
    "### Best Fit Model\n",
    "print(\"Fitting for the Best-Fit Model\")\n",
    "best_fit_idx = df.Root_Mean_Square_Error.idxmin()\n",
    "best_fit_algo_name = df.iloc[best_fit_idx][\"Estimator\"]\n",
    "best_fit_feature_type = df.iloc[best_fit_idx][\"Feature_Selection\"]\n",
    "\n",
    "model = algorithms[best_fit_algo_name]\n",
    "cols = features[best_fit_feature_type]\n",
    "X = final[cols]\n",
    "y = m_giving_logp1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "results = model.fit(X_train, y_train)\n",
    "\n",
    "# save\n",
    "with open(\"bestfit_results_%s_%s.pkl\" %(best_fit_algo_name, best_fit_feature_type),\"wb\") as f:\n",
    "    pickle.dump(results,f)\n",
    "with open(\"bestfit_model_%s_%s.pkl\" %(best_fit_algo_name, best_fit_feature_type),\"wb\") as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75c62e81-138e-4ed2-9bee-acd4f2e8ae8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature_Selection         rfecv_xgb\n",
       "N_Features                       35\n",
       "Estimator                      XGBR\n",
       "Root_Mean_Square_Error     0.321809\n",
       "Name: 32, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[(key, len(features[key]), key1, model_stats[key][key1]) for key in model_stats.keys() for key1 in model_stats[key].keys()]\n",
    "df.sort_values([\"Root_Mean_Square_Error\"])\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8401c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False\n",
    "if run:\n",
    "    model = xgb.XGBRFRegressor()\n",
    "    cols = xcol_rfecv_xgb\n",
    "\n",
    "    X = final[cols]\n",
    "    y = m_giving_logp1\n",
    "    \n",
    "    # Creating a training set index by partitioning the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=folds, scoring='neg_root_mean_squared_error')\n",
    "    results = model.fit(X_train, y_train)\n",
    "    y_pred = results.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86cf9ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Selection</th>\n",
       "      <th>N_Features</th>\n",
       "      <th>Estimator</th>\n",
       "      <th>Root_Mean_Square_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>44</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.401143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all</td>\n",
       "      <td>44</td>\n",
       "      <td>GBR</td>\n",
       "      <td>0.337614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>44</td>\n",
       "      <td>XGBR</td>\n",
       "      <td>0.322109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all</td>\n",
       "      <td>44</td>\n",
       "      <td>XGBRF</td>\n",
       "      <td>0.360659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all</td>\n",
       "      <td>44</td>\n",
       "      <td>DTR</td>\n",
       "      <td>0.440879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>var_1</td>\n",
       "      <td>34</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.401315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>var_1</td>\n",
       "      <td>34</td>\n",
       "      <td>GBR</td>\n",
       "      <td>0.337223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>var_1</td>\n",
       "      <td>34</td>\n",
       "      <td>XGBR</td>\n",
       "      <td>0.322101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>var_1</td>\n",
       "      <td>34</td>\n",
       "      <td>XGBRF</td>\n",
       "      <td>0.361452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>var_1</td>\n",
       "      <td>34</td>\n",
       "      <td>DTR</td>\n",
       "      <td>0.441052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>var_10</td>\n",
       "      <td>14</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.404426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>var_10</td>\n",
       "      <td>14</td>\n",
       "      <td>GBR</td>\n",
       "      <td>0.336948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>var_10</td>\n",
       "      <td>14</td>\n",
       "      <td>XGBR</td>\n",
       "      <td>0.325208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>var_10</td>\n",
       "      <td>14</td>\n",
       "      <td>XGBRF</td>\n",
       "      <td>0.359143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>var_10</td>\n",
       "      <td>14</td>\n",
       "      <td>DTR</td>\n",
       "      <td>0.435895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>var_5</td>\n",
       "      <td>29</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.401899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>var_5</td>\n",
       "      <td>29</td>\n",
       "      <td>GBR</td>\n",
       "      <td>0.336770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>var_5</td>\n",
       "      <td>29</td>\n",
       "      <td>XGBR</td>\n",
       "      <td>0.322544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>var_5</td>\n",
       "      <td>29</td>\n",
       "      <td>XGBRF</td>\n",
       "      <td>0.361865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>var_5</td>\n",
       "      <td>29</td>\n",
       "      <td>DTR</td>\n",
       "      <td>0.441021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>f_stat</td>\n",
       "      <td>33</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.401419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>f_stat</td>\n",
       "      <td>33</td>\n",
       "      <td>GBR</td>\n",
       "      <td>0.337798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>f_stat</td>\n",
       "      <td>33</td>\n",
       "      <td>XGBR</td>\n",
       "      <td>0.322421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>f_stat</td>\n",
       "      <td>33</td>\n",
       "      <td>XGBRF</td>\n",
       "      <td>0.361940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>f_stat</td>\n",
       "      <td>33</td>\n",
       "      <td>DTR</td>\n",
       "      <td>0.438511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>r_pearson</td>\n",
       "      <td>14</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.405911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>r_pearson</td>\n",
       "      <td>14</td>\n",
       "      <td>GBR</td>\n",
       "      <td>0.338787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>r_pearson</td>\n",
       "      <td>14</td>\n",
       "      <td>XGBR</td>\n",
       "      <td>0.326627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>r_pearson</td>\n",
       "      <td>14</td>\n",
       "      <td>XGBRF</td>\n",
       "      <td>0.363517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>r_pearson</td>\n",
       "      <td>14</td>\n",
       "      <td>DTR</td>\n",
       "      <td>0.426460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rfecv_xgb</td>\n",
       "      <td>35</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.401125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rfecv_xgb</td>\n",
       "      <td>35</td>\n",
       "      <td>GBR</td>\n",
       "      <td>0.337614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rfecv_xgb</td>\n",
       "      <td>35</td>\n",
       "      <td>XGBR</td>\n",
       "      <td>0.321809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rfecv_xgb</td>\n",
       "      <td>35</td>\n",
       "      <td>XGBRF</td>\n",
       "      <td>0.359443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>rfecv_xgb</td>\n",
       "      <td>35</td>\n",
       "      <td>DTR</td>\n",
       "      <td>0.442437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>rfecv_lm</td>\n",
       "      <td>6</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.414862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>rfecv_lm</td>\n",
       "      <td>6</td>\n",
       "      <td>GBR</td>\n",
       "      <td>0.396214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>rfecv_lm</td>\n",
       "      <td>6</td>\n",
       "      <td>XGBR</td>\n",
       "      <td>0.388027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>rfecv_lm</td>\n",
       "      <td>6</td>\n",
       "      <td>XGBRF</td>\n",
       "      <td>0.404111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>rfecv_lm</td>\n",
       "      <td>6</td>\n",
       "      <td>DTR</td>\n",
       "      <td>0.449337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_Selection  N_Features Estimator  Root_Mean_Square_Error\n",
       "0                all          44        LR                0.401143\n",
       "1                all          44       GBR                0.337614\n",
       "2                all          44      XGBR                0.322109\n",
       "3                all          44     XGBRF                0.360659\n",
       "4                all          44       DTR                0.440879\n",
       "5              var_1          34        LR                0.401315\n",
       "6              var_1          34       GBR                0.337223\n",
       "7              var_1          34      XGBR                0.322101\n",
       "8              var_1          34     XGBRF                0.361452\n",
       "9              var_1          34       DTR                0.441052\n",
       "10            var_10          14        LR                0.404426\n",
       "11            var_10          14       GBR                0.336948\n",
       "12            var_10          14      XGBR                0.325208\n",
       "13            var_10          14     XGBRF                0.359143\n",
       "14            var_10          14       DTR                0.435895\n",
       "15             var_5          29        LR                0.401899\n",
       "16             var_5          29       GBR                0.336770\n",
       "17             var_5          29      XGBR                0.322544\n",
       "18             var_5          29     XGBRF                0.361865\n",
       "19             var_5          29       DTR                0.441021\n",
       "20            f_stat          33        LR                0.401419\n",
       "21            f_stat          33       GBR                0.337798\n",
       "22            f_stat          33      XGBR                0.322421\n",
       "23            f_stat          33     XGBRF                0.361940\n",
       "24            f_stat          33       DTR                0.438511\n",
       "25         r_pearson          14        LR                0.405911\n",
       "26         r_pearson          14       GBR                0.338787\n",
       "27         r_pearson          14      XGBR                0.326627\n",
       "28         r_pearson          14     XGBRF                0.363517\n",
       "29         r_pearson          14       DTR                0.426460\n",
       "30         rfecv_xgb          35        LR                0.401125\n",
       "31         rfecv_xgb          35       GBR                0.337614\n",
       "32         rfecv_xgb          35      XGBR                0.321809\n",
       "33         rfecv_xgb          35     XGBRF                0.359443\n",
       "34         rfecv_xgb          35       DTR                0.442437\n",
       "35          rfecv_lm           6        LR                0.414862\n",
       "36          rfecv_lm           6       GBR                0.396214\n",
       "37          rfecv_lm           6      XGBR                0.388027\n",
       "38          rfecv_lm           6     XGBRF                0.404111\n",
       "39          rfecv_lm           6       DTR                0.449337"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9fe66f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('.py39_scikit': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "182b72de6a7fc364a5310487655b0e5f592a8e241d778628074080a7151d467c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
