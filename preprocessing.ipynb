{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2744119-c7de-44c1-8f53-faf974f72eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from configparser import ConfigParser\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b035d8-bfa6-4b12-b329-63c38ae4fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path and filename variables\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\Rmittal\\\\CCS\\\\Internal - Analytics - Shared Drive\\\\1. Shared Drive\\\\Clients\"\n",
    "subdir = \"Raw Client Data\" \n",
    "clients = \"Thomas College\"\n",
    "file_name = \"Section 3 constituent level data 01312024.xlsx\"\n",
    "sheet_name = \"\"\n",
    "\n",
    "gui=False\n",
    "if gui:\n",
    "    file_path = input(\"Enter file path:\")\n",
    "    file_name = input(\"Enter file name:\")\n",
    "    sheet_name = input(\"Enter sheet name if Excel spreadsheet. Hit Enter if only single sheet:\")\n",
    "\n",
    "if sheet_name=='':\n",
    "    sheet_name = None\n",
    "\n",
    "file_details = {\"file_name\": file_name, \"sheet_name\": sheet_name}\n",
    "file = \"%s\\\\%s\\\\%s\\\\%s\" %(file_path, clients, subdir, file_name)\n",
    "prefix = \".\".join(file_name.split(\".\")[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d591e-0f96-4d9c-ae8d-578d0a6bcb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_encoding = False\n",
    "if detect_encoding:\n",
    "    with open(file, 'rb') as f:\n",
    "        raw_data = f.readline()\n",
    "    raw_data_encoding = chardet.detect(raw_data)['encoding']\n",
    "    print(raw_data_encoding)\n",
    "    \n",
    "    fext = file.split(\".\")[-1]\n",
    "    if fext.lower() == \"xlsx\":\n",
    "        df = pd.read_excel(file, file_details[\"sheet_name\"])\n",
    "    elif fext.lower() == \"csv\":\n",
    "        df = pd.read_csv(file, encoding=raw_data_encoding)\n",
    "\n",
    "# Define the column names and their corresponding data types\n",
    "#dtype_dict = {\"Donor ID\": str}  # Replace 'column_with_leading_zeros' with the actual column name\n",
    "\n",
    "df = pd.read_excel(file)\n",
    "df = pd.read_excel(file, dtype={col: str for col in df.columns if 'id' in col.lower()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16de02bc-ee82-4a3c-a22f-e3daa639bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For the gifts file\n",
    "#[(key, df[key].value_counts()) for key in df.keys() if \"id\" in key.lower()]\n",
    "#df = df.drop(columns=columns_to_drop)\n",
    "#df = df.drop(columns=[\"filename\"])\n",
    "#df.to_csv(\"../nsf/national_scleroderma_foundation_gifts_clean_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b34a2e6d-9a3d-4e1b-842c-af473651a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_giving_logp1 = np.log1p(df[\"total_with_hard_soft_credit\"])/np.log(10)\n",
    "#m_giving_logp1.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1a63b08-91c2-48f6-9c33-ed245824bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a917c85-3a5a-45c0-a965-e3d91fdb1d1f",
   "metadata": {},
   "source": [
    "### Preprocessing before mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a3ba96e-a50e-49aa-8062-72f3ecb4e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False\n",
    "if run:\n",
    "    df = df.rename(columns={\"zip\": \"zip_raw\"})\n",
    "    df[\"solicit_codes\"] =  df.filter(like='solicit').notna().any(axis=1).astype(int)\n",
    "    df[\"five_year_giving\"] =  df[\"total_giving_2023\"] + df[\"total_giving_2022\"] + df[\"total_giving_2021\"] \\\n",
    "                            + df[\"total_giving_2020\"] + df[\"total_giving_2019\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0adb12b8-b1a0-4100-98b7-8e06eda239e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[(key, df[key].value_counts()) for key in df.keys() if \"constituent\" in key.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa8ecf29-d040-4943-ad78-f2f207d3a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_csv(\"./thomas_college_constit_mapping.csv\")\n",
    "column_mapping = {row[\"file_columns\"]: row[\"expected_columns\"] \\\n",
    "                  for index, row in mapping.iterrows() if row[\"file_columns\"]!=\"not_found\"}\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "df = df[list(column_mapping.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d5c47a-dd8c-4050-91d9-efd16bce663f",
   "metadata": {},
   "source": [
    "### Preprocessing after mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b2a03484-e478-437a-81e5-77e43473773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class_year\"] = df[\"class_year\"].str.split(\"'\",expand=True)[1]\n",
    "df[\"class_year\"] = df[\"class_year\"].fillna(np.nan).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2f041066-17ad-41aa-a2a4-fba68f409367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"class_year\"] = np.where(((df[\"class_year\"] > 50) & (~df[\"class_year\"].isna())), \"19\" + df[\"class_year\"].astype(str), \\\n",
    "#                            \"20\" + df[\"class_year\"].astype(str))\n",
    "mask = ~df[\"class_year\"].isna()\n",
    "df.loc[mask, \"class_year\"] = np.where((df.loc[mask, \"class_year\"] > 25),\n",
    "                                      \"19\" + df.loc[mask, \"class_year\"].astype(str),\n",
    "                                      \"20\" + df.loc[mask, \"class_year\"].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d463471b-60c6-4359-97e0-701b372b5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_datetime = list(df.select_dtypes(include=['datetime']).keys())\n",
    "for col in cols_datetime:\n",
    "    df[col] = pd.to_datetime(df[col]).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "94f76f80-9829-4a58-bbcd-c6f19ca3e443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[62111, 62111, 62111, 62110]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Exploratory Analysis\n",
    "#df.tail()\n",
    "#df = df.loc[0:2674626]\n",
    "df_split = np.array_split(df, 4)\n",
    "[len(df_split[i]) for i in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c603b2-f1df-42cf-9fee-4ae3facd29c0",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a2e7e99a-04b8-487b-8803-2be10c238069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_split(df, file, chunk_size=None):\n",
    "    '''\n",
    "    Splits files into parts, or in chunk_size\n",
    "    '''\n",
    "    if not file:\n",
    "        print(\"Provide a File\")\n",
    "        return False\n",
    "    if not chunk_size:\n",
    "        print(\"Provide non-zero chunk_size in MB\")\n",
    "        return False\n",
    "    \n",
    "    ### File Attributes\n",
    "    fsize = os.path.getsize(file)\n",
    "    fdir, fname = os.path.split(file)\n",
    "    fname = os.path.splitext(fname)[0]\n",
    "    fext = file.split(\".\")[-1]\n",
    "\n",
    "    ### Determine the number of parts\n",
    "    chunk_size = chunk_size*1E+6\n",
    "    parts = int(np.floor(fsize/chunk_size))\n",
    "    \n",
    "    if chunk_size > fsize:\n",
    "        raise ValueError('Chunk size cannot be greater than file size')\n",
    "    else:\n",
    "        print(\"The file is being split into %d files\" %parts)\n",
    "        \n",
    "    df_split = np.array_split(df, parts)\n",
    "\n",
    "    for i in range(parts):\n",
    "        print(\"part %d\" %i)\n",
    "        if fext.lower() == \"xlsx\":\n",
    "            df_split[i].to_excel(\"%s/%s_%d.%s\" %(fdir, fname, i+1, fext), index=False)\n",
    "        elif fext.lower() == \"csv\":\n",
    "            df_split[i].to_csv(\"%s/%s_%d.%s\" %(fdir, fname, i+1, fext), index=False)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "857a80f5-b8fd-4f72-9bfd-f576bfe47077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_split(df, file, chunk_size=50)\n",
    "df.to_csv(\"./thomas_college_constit_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3366337a-321f-4481-b7ff-d922b5528073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['history_of_volunteer'] = df['history_of_volunteer'].astype(str)\n",
    "#df['history_of_volunteer'].str.len().value_counts()\n",
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c5ac2e7c-0723-4b05-bfbf-ce72a0243c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>constituent_id</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>modification_date</th>\n",
       "      <th>key_indicator</th>\n",
       "      <th>deceased</th>\n",
       "      <th>prefix</th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>suffix</th>\n",
       "      <th>...</th>\n",
       "      <th>first_gift_amount</th>\n",
       "      <th>first_gift_date</th>\n",
       "      <th>First Gift Fund</th>\n",
       "      <th>most_recent_gift_amount</th>\n",
       "      <th>most_recent_gift_date</th>\n",
       "      <th>Last Gift Fund</th>\n",
       "      <th>Largest Gift Amount</th>\n",
       "      <th>Largest Gift Date</th>\n",
       "      <th>Largest Gift Fund</th>\n",
       "      <th>number_of_special_events_attended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15197</td>\n",
       "      <td>2004-03-04</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>Indiv</td>\n",
       "      <td>No</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>Tricia</td>\n",
       "      <td>E</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11550</td>\n",
       "      <td>2004-03-04</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>Indiv</td>\n",
       "      <td>No</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>Diane</td>\n",
       "      <td>C</td>\n",
       "      <td>Abbott-Cookson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14266</td>\n",
       "      <td>2004-03-04</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>Indiv</td>\n",
       "      <td>No</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>Arlene</td>\n",
       "      <td>Mildred</td>\n",
       "      <td>Abrams</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28105</td>\n",
       "      <td>2004-03-04</td>\n",
       "      <td>2023-04-18</td>\n",
       "      <td>Indiv</td>\n",
       "      <td>No</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Robert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abrams</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17845</td>\n",
       "      <td>2004-03-04</td>\n",
       "      <td>2012-02-10</td>\n",
       "      <td>Indiv</td>\n",
       "      <td>No</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abreu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   constituent_id creation_date modification_date key_indicator deceased  \\\n",
       "0           15197    2004-03-04        2023-01-06         Indiv       No   \n",
       "1           11550    2004-03-04        2024-01-08         Indiv       No   \n",
       "2           14266    2004-03-04        2024-01-08         Indiv       No   \n",
       "3           28105    2004-03-04        2023-04-18         Indiv       No   \n",
       "4           17845    2004-03-04        2012-02-10         Indiv       No   \n",
       "\n",
       "  prefix first_name middle_name       last_name suffix  ... first_gift_amount  \\\n",
       "0    Ms.     Tricia           E          Abbott    NaN  ...               NaN   \n",
       "1    Ms.      Diane           C  Abbott-Cookson    NaN  ...               NaN   \n",
       "2   Mrs.     Arlene     Mildred          Abrams    NaN  ...               NaN   \n",
       "3    Mr.     Robert         NaN          Abrams    NaN  ...               NaN   \n",
       "4    Mr.    Anthony         NaN           Abreu    NaN  ...               NaN   \n",
       "\n",
       "  first_gift_date First Gift Fund  most_recent_gift_amount  \\\n",
       "0             NaT             NaN                      NaN   \n",
       "1             NaT             NaN                      NaN   \n",
       "2             NaT             NaN                      NaN   \n",
       "3             NaT             NaN                      NaN   \n",
       "4             NaT             NaN                      NaN   \n",
       "\n",
       "  most_recent_gift_date Last Gift Fund Largest Gift Amount Largest Gift Date  \\\n",
       "0                   NaT            NaN                 NaN               NaT   \n",
       "1                   NaT            NaN                 NaN               NaT   \n",
       "2                   NaT            NaN                 NaN               NaT   \n",
       "3                   NaT            NaN                 NaN               NaT   \n",
       "4                   NaT            NaN                 NaN               NaT   \n",
       "\n",
       "  Largest Gift Fund number_of_special_events_attended  \n",
       "0               NaN                                 0  \n",
       "1               NaN                                 0  \n",
       "2               NaN                                 0  \n",
       "3               NaN                                 0  \n",
       "4               NaN                                 0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3214ed-5bd4-4eec-88c0-db8e2c612c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[df.groupby(\"constituent_id\")[\"constituent_id\"].transform('size') > 1]\n",
    "df_subset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('.py39_scikit': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "182b72de6a7fc364a5310487655b0e5f592a8e241d778628074080a7151d467c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
